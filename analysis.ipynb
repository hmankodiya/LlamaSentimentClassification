{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"tyqiangz/multilingual-sentiments\", 'all', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_dataset.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yang memerlukan pemerhatian dan tindakan serius</td>\n",
       "      <td>malaya</td>\n",
       "      <td>malay</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentiasa memikirkan dan merancang inisiatif ba...</td>\n",
       "      <td>malaya</td>\n",
       "      <td>malay</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kita akan tengok daripada pelbagai aspek supay...</td>\n",
       "      <td>malaya</td>\n",
       "      <td>malay</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>justeru asean perlu mengambil tindakan sebagai...</td>\n",
       "      <td>malaya</td>\n",
       "      <td>malay</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@_Niiar_ Jangan punah dulu, aku belum ke labua...</td>\n",
       "      <td>malaya</td>\n",
       "      <td>malay</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270394</th>\n",
       "      <td>RT @user: #أيفون_البروفيسورمسابقة على أيفون7 أ...</td>\n",
       "      <td>sem_eval_2017</td>\n",
       "      <td>arabic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270395</th>\n",
       "      <td>اللهم أنت السلام ومنك السلام تباركت يا ذا الجل...</td>\n",
       "      <td>sem_eval_2017</td>\n",
       "      <td>arabic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270396</th>\n",
       "      <td>على وقع حمى الانتخابات الأميركية ويكليكس تكشف ...</td>\n",
       "      <td>sem_eval_2017</td>\n",
       "      <td>arabic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270397</th>\n",
       "      <td>@user @user على البي سي\"ويندوز 10\"</td>\n",
       "      <td>sem_eval_2017</td>\n",
       "      <td>arabic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270398</th>\n",
       "      <td>عندي وحده تشبه هاري بوتر يا انها كيوتيه😨!😭💗</td>\n",
       "      <td>sem_eval_2017</td>\n",
       "      <td>arabic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270399 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text         source  \\\n",
       "0         yang memerlukan pemerhatian dan tindakan serius         malaya   \n",
       "1       sentiasa memikirkan dan merancang inisiatif ba...         malaya   \n",
       "2       Kita akan tengok daripada pelbagai aspek supay...         malaya   \n",
       "3       justeru asean perlu mengambil tindakan sebagai...         malaya   \n",
       "4       @_Niiar_ Jangan punah dulu, aku belum ke labua...         malaya   \n",
       "...                                                   ...            ...   \n",
       "270394  RT @user: #أيفون_البروفيسورمسابقة على أيفون7 أ...  sem_eval_2017   \n",
       "270395  اللهم أنت السلام ومنك السلام تباركت يا ذا الجل...  sem_eval_2017   \n",
       "270396  على وقع حمى الانتخابات الأميركية ويكليكس تكشف ...  sem_eval_2017   \n",
       "270397                 @user @user على البي سي\"ويندوز 10\"  sem_eval_2017   \n",
       "270398        عندي وحده تشبه هاري بوتر يا انها كيوتيه😨!😭💗  sem_eval_2017   \n",
       "\n",
       "       language  label  \n",
       "0         malay      0  \n",
       "1         malay      0  \n",
       "2         malay      0  \n",
       "3         malay      0  \n",
       "4         malay      1  \n",
       "...         ...    ...  \n",
       "270394   arabic      1  \n",
       "270395   arabic      0  \n",
       "270396   arabic      2  \n",
       "270397   arabic      1  \n",
       "270398   arabic      0  \n",
       "\n",
       "[270399 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(train_dataset.to_dict())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import load_pretrained_gpt2_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_pretrained_gpt2_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [51, 316, 15042, 275, 10102, 393, 648, 300, 391, 1066, 263, 600, 993, 479, 5350, 479, 1045, 256, 461, 731, 377, 11, 256, 461, 1888, 283, 11, 256, 461, 16486, 84, 11, 256, 461, 1458, 315], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(df['text'][2500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'عندي وحده تشبه هاري بوتر يا انها كيوتيه😨!😭💗'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][270398]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    read_yaml,\n",
    "    get_tokenizer_config,\n",
    "    get_dataset_config,\n",
    "    DEVICE,\n",
    ")\n",
    "from gpt_dataset import GPTDataset\n",
    "from model import load_model, load_tokenizer, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5145 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "config = read_yaml('./train_config.yaml')\n",
    "\n",
    "tokenizer_name, tokenizer_path, tokenizer_config = get_tokenizer_config(config)\n",
    "tokenizer = load_tokenizer(tokenizer_name, tokenizer_path)\n",
    "\n",
    "dataset_path, dataset_desc, dataset_config = get_dataset_config(config)\n",
    "train_dataset = GPTDataset(\n",
    "    filepath=dataset_path, tokenizer=tokenizer, **dataset_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD alwa'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./dataset/the-verdict.txt', 'r') as F:\n",
    "    file_text = F.read()\n",
    "file_text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from argparse import ArgumentParser\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "from utils import (\n",
    "    read_yaml,\n",
    "    get_model_config,\n",
    "    get_tokenizer_config,\n",
    "    get_split_config,\n",
    "    get_dataset_config,\n",
    "    get_trainer_config,\n",
    "    get_prediction_config,\n",
    "    get_lora_config,\n",
    "    _handle_seed,\n",
    "    DEVICE,\n",
    ")\n",
    "from sentiment_dataset import SentimentDataset\n",
    "from model import (\n",
    "    load_model,\n",
    "    load_tokenizer,\n",
    "    load_lora_model,\n",
    "    predict,\n",
    "    compute_metrics,\n",
    "    METRICS_DICT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_yaml(\"./configs/predict_config_llama_lora.yaml\")\n",
    "# config = read_yaml(\"./configs/predict_config_gpt2.yaml\")\n",
    "# config = read_yaml(\"./configs/predict_config_llama.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name, tokenizer_path, tokenizer_config = get_tokenizer_config(config)\n",
    "tokenizer = load_tokenizer(\n",
    "    tokenizer_name=tokenizer_name,\n",
    "    tokenizer_path=tokenizer_path,\n",
    "    tokenizer_config=tokenizer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_desc, (train_split_config, val_split_config, test_split_config) = (\n",
    "    get_split_config(config)\n",
    ")\n",
    "\n",
    "test_dataset_path, test_dataset_language, test_dataset_config = (\n",
    "    get_dataset_config(test_split_config)\n",
    ")\n",
    "test_dataset = SentimentDataset(\n",
    "    dataset_path=test_dataset_path,\n",
    "    dataset_language=test_dataset_language,\n",
    "    split_type=\"test\",\n",
    "    tokenizer=tokenizer,\n",
    "    **test_dataset_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdce31eb34f467ead754aa35ab41b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name, model_path, base_model_path, model_config = get_model_config(config)\n",
    "model_config.update(dict(pad_token_id=tokenizer.pad_token_id))\n",
    "model = load_model(\n",
    "    model_string=model_name,\n",
    "    model_path=model_path,\n",
    "    base_model_path=base_model_path,\n",
    "    model_config=model_config,\n",
    ")\n",
    "model = model.to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_samples = [\n",
    "    \"this is a bad product\",\n",
    "    \"this the nice product\",\n",
    "    \"this is a best product\",\n",
    "    \"how are you?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hmankodi/bitsandbytes/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2, 0, 0, 1]), ['negative', 'positive', 'positive', 'neutral'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predcitions = predict(\n",
    "    model, tokenizer, prompt_samples, device=DEVICE,\n",
    ")\n",
    "predcitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from model import METRICS_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=test_dataset_config.get(\"padding\", True),\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=lambda x: (compute_metrics(x, METRICS_DICT)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1809' max='1809' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1809/1809 11:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0556640625,\n",
       " 'eval_model_preparation_time': 0.0045,\n",
       " 'eval_accuracy': 0.68766,\n",
       " 'eval_auc': 0.85569,\n",
       " 'eval_runtime': 690.2538,\n",
       " 'eval_samples_per_second': 20.956,\n",
       " 'eval_steps_per_second': 2.621}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lora_params(model):\n",
    "    \"\"\"\n",
    "    Prints and counts the total trainable parameters for LoRA layers in a model.\n",
    "    \"\"\"\n",
    "    total_params = 0\n",
    "    print(\"LoRA Trainable Parameters:\\n\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            num_params = param.numel()\n",
    "            total_params += num_params\n",
    "            print(f\"{name}: {num_params} parameters\")\n",
    "    \n",
    "    print(f\"\\nTotal LoRA trainable parameters: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3409342464"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(i.numel() for i in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 12,288 || all params: 6,647,345,152 || trainable%: 0.0002\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
